{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29370cef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:39.723106Z",
     "start_time": "2024-05-09T14:49:34.987618Z"
    },
    "code_folding": [
     3,
     11,
     19
    ]
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def setup_display(width=95, fontsize=16):\n",
    "    \"\"\"\n",
    "    Sets window width and markdown fontsize for Jupyter notebook. Width is % of window.\n",
    "    \"\"\"\n",
    "    display(HTML(\"<style>.container { width:\"+str(width)+\"% !important; }</style>\"))\n",
    "    display(HTML(\"<style>.rendered_html { font-size: \"+str(fontsize)+\"px; }</style>\"))\n",
    "    return None\n",
    "\n",
    "def source(fn):\n",
    "    import inspect\n",
    "    print(inspect.getsource(fn))\n",
    "    return None\n",
    "\n",
    "import sys\n",
    "# Adding the Winnie package's directory to your path\n",
    "winnie_path = '../'\n",
    "\n",
    "if winnie_path not in sys.path:\n",
    "    sys.path.append(winnie_path)\n",
    "\n",
    "##################\n",
    "import numpy as np\n",
    "import glob\n",
    "import winnie\n",
    "from winnie.plot import animate_quick_implot, quick_implot, mpl, plt\n",
    "from spaceKLIP import database\n",
    "import webbpsf\n",
    "import astropy.units as u\n",
    "\n",
    "setup_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f0e079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:39.832462Z",
     "start_time": "2024-05-09T14:49:39.724722Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prep the SpaceRDI object:\n",
    "distance = 9.714 # Distance to your target in parsecs\n",
    "\n",
    "base_dir = './aumic_rdi_example/'\n",
    "input_dir = f'{base_dir}coadded/'\n",
    "output_dir = f'{base_dir}WinnieRDI/'\n",
    "data_ext = 'calints'\n",
    "fitsfiles = np.sort(glob.glob(f'{input_dir}*{data_ext}.fits')) # Populate a file list\n",
    "\n",
    "# Initialize the spaceKLIP database\n",
    "Database = database.Database(output_dir)\n",
    "Database.verbose = False\n",
    "Database.read_jwst_s012_data(datapaths=fitsfiles,\n",
    "                             psflibpaths=None,\n",
    "                             bgpaths=None)\n",
    "\n",
    "# Create the SpaceRDI object we'll use to carry out RDI\n",
    "wdb = winnie.SpaceRDI(Database, data_ext, overwrite=True, verbose=True, pad_data='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64862190",
   "metadata": {},
   "source": [
    "The prepare_convolution method in the next cell should only be executed if you need to PSF-convolve models at some point. \n",
    "\n",
    "Note: you can also run this after loading your first concatenation. However, it only needs to be run once for a given winnie.SpaceRDI object. If you want to turn this off after turning it on for some reason, just re-create the SpaceRDI object. \n",
    "\n",
    "A few details to keep in mind:\n",
    "\n",
    "- Your PSF grid parameters — fov_pixels, nr (the number of radial grid samples), and ntheta (the number of azimuthal grid samples) — will matter a lot more for disks with flux near or across the IWA region — like an edge-on disk. \n",
    "\n",
    "- For a ring-like disk that's moderately inclined, settings like fov_pixels\\~100, nr\\~5, ntheta=4, should be sufficient and will speed up your forward modeling.\n",
    "\n",
    "- For scattered light (~ NIRCam), generating PSFs using a spectrum comparable to that of the science target star should be a reasonable approximation.\n",
    "\n",
    "- For thermal emission (~ MIRI), you may want to use something like a blackbody approximating the temperature of the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69a9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:40.132916Z",
     "start_time": "2024-05-09T14:49:39.833871Z"
    }
   },
   "outputs": [],
   "source": [
    "# Spectrum to assume for the convolution PSFs; ck04 doesn't have an M1, so we're just using an M0V instead.\n",
    "spec_synphot = webbpsf.specFromSpectralType('M0V', catalog='ck04')\n",
    "\n",
    "wdb.prepare_convolution(spec_synphot, fov_pixels=201, osamp=2, psf_grid_kwargs=dict(nr=10, ntheta=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388008e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:47.833329Z",
     "start_time": "2024-05-09T14:49:40.135380Z"
    }
   },
   "outputs": [],
   "source": [
    "# The first time loading each concatenation will take ~5-10 minutes for generating the PSF grid. Reloading later, it should be much quicker.\n",
    "wdb.load_concat(0)\n",
    "\n",
    "# Run a basic RDI reduction with default settings.\n",
    "rdi_reduc = wdb.run_rdi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82afa4ae",
   "metadata": {},
   "source": [
    "# PSF grid convolution and forward modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314d168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:49.721103Z",
     "start_time": "2024-05-09T14:49:47.834847Z"
    },
    "code_folding": [
     9
    ]
   },
   "outputs": [],
   "source": [
    "# Disk modeling functions and imports\n",
    "\n",
    "from scipy import ndimage\n",
    "from winnie.utils import px_size_to_ang_size, ang_size_to_proj_sep, median_filter_sequence\n",
    "import vip_hci as vip\n",
    "from vip_hci.fm import ScatteredLightDisk, Phase_function\n",
    "from astropy import convolution\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def grater_2hg_disk_model(r0, h0, ain, aout, pa, incl, g1, g2, wg1,\n",
    "                           e=0., omega=0., gamma=2., beta=1.,\n",
    "                           cent=np.array([160.,160.]),\n",
    "                           distance=10., nx=320, ny=320,\n",
    "                           pxscale=0.063*u.arcsec/u.pixel, \n",
    "                           accuracy=None, rmax_accuracy=None,\n",
    "                           halfNbSlices=25, polar=False, flux_max=None):\n",
    "    \"\"\"\n",
    "    A simple ring-like disk morphology based on Augereau et al. (1999) and assuming a linear combo of two H-G SPFs as the scattering phase function.\n",
    "    \n",
    "    r0: fiducial radius in au\n",
    "    h0: technically h0/r0 — the ratio of scale height to fiducial radius at the fiducial radius\n",
    "    ain: radial density power law exponent interior to r0\n",
    "    aout: radial density power law exponent exterior to r0\n",
    "    pa: disk position angle in degrees\n",
    "    incl: disk inclination in degrees\n",
    "    g1: 1st Henyey-Greenstein asymmetry parameter\n",
    "    g2: 2nd Henyey-Greenstein asymmetry parameter\n",
    "    wg1: Weight for the SPF term with asymmetry parameter g1 (value in range 0-1); wg2 is 1-wg1\n",
    "    e: eccentricity\n",
    "    omega: argument of pericenter in degrees\n",
    "    gamma: vertical density exponent (gamma = 2 for gaussian)\n",
    "    beta: disk radial flaring exponent (beta = 1 for linear)\n",
    "    \n",
    "    cent: the pixel position for the center of the disk (generally the location of the star in the data)\n",
    "    distance: distance to the target in parsecs\n",
    "    nx: number of x-axis pixels for the image\n",
    "    ny: number of y-axis pixels for the image\n",
    "    pxscale: the pixel scale for the data; either a float (must be arcsec/pixel) or astropy units (any units that can be cast to arcsec/pixel)\n",
    "    accuracy: the numerical accuracy for the model; pixels with density below this value will be set to zero\n",
    "    rmax_accuracy: if accuracy is None, the model's accuracy is set such that non-zero values are achieved to this separation (in au)\n",
    "    halfNbSlices: the number of planar slices to compute above and below the disk midplane\n",
    "    polar: if True, a simple bell-shaped polarization curve is used to generate a polarized intensity image\n",
    "    flux_max: if not None, normalize the model image so that this is the maximum value.\n",
    "    \"\"\"\n",
    "    \n",
    "    def dont_actually_check_inclination():\n",
    "        \"\"\"\n",
    "        VIP's ScatteredLightDisk will normally decrease disk inclination if too high.\n",
    "        This will cause issues for optimization, so we'd rather live with the artifacts / etc.\n",
    "        Instead, we just tell VIP that the incl is good whenever it checks.\n",
    "        \"\"\"\n",
    "        return None\n",
    " \n",
    "    if accuracy is None:\n",
    "        if rmax_accuracy is None:\n",
    "            im_corner_dists = np.hypot(*(np.array([[0, 0], [0, ny-1], [nx-1, 0], [nx-1, ny-1]])-cent).T)\n",
    "            rmax_accuracy = ang_size_to_proj_sep(px_size_to_ang_size(np.max(im_corner_dists), pxscale), distance).value\n",
    "        accuracy = (rmax_accuracy/r0)**(aout)\n",
    "            \n",
    "    spf = {'name':'DoubleHG', 'g': [g1, g2], 'weight': wg1, 'polar': polar}\n",
    "    dens = {'name': '2PowerLaws', 'ain': ain, 'aout': aout, 'a': r0, 'ksi0':h0*r0,\n",
    "            'e': e, 'gamma': gamma, 'beta': beta, 'accuracy': accuracy}\n",
    "    \n",
    "    vip_disk = ScatteredLightDisk(nx=nx, ny=ny, distance=distance,\n",
    "                                  itilt=incl, pxInArcsec=(pxscale << u.arcsec/u.pixel).value,\n",
    "                                  pa=pa-180., omega=omega,\n",
    "                                  density_dico=dens, spf_dico=spf, flux_max=flux_max)\n",
    "    \n",
    "    vip_disk.dust_density.accuracy = accuracy\n",
    "    vip_disk.dust_density.dust_distribution_calc.rmax = vip_disk.dust_density.dust_distribution_calc.a*accuracy**(1/vip_disk.dust_density.dust_distribution_calc.aout)\n",
    "    vip_disk.check_inclination = dont_actually_check_inclination\n",
    "    disk = vip_disk.compute_scattered_light(halfNbSlices=halfNbSlices)\n",
    "\n",
    "    # For disks with material coincident with the stellar position along the line of sight, VIP returns an image with a plus-sign shaped region of zeros at the star's position\n",
    "    # The below is a quick work-around to correct this. Very likely makes zero difference following PSF-convolution\n",
    "    c_vip = vip.var.frame_center(disk)[::-1]\n",
    "    disk[c_vip[1]-1:c_vip[1]+2, c_vip[0]] = np.nan\n",
    "    disk[c_vip[1], c_vip[0]-1:c_vip[0]+2] = np.nan\n",
    "    disk = convolution.interpolate_replace_nans(disk, np.ones((3,3)))\n",
    "    dx, dy = cent[0]-c_vip[0], cent[1]-c_vip[1]\n",
    "    if dx != 0 or dy != 0:\n",
    "        disk = ndimage.shift(disk, [dy, dx], order=5)\n",
    "    return disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761bce01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:51.394200Z",
     "start_time": "2024-05-09T14:49:49.722726Z"
    }
   },
   "outputs": [],
   "source": [
    "# Disk parameters (see grater_hong_disk_model docstring)\n",
    "# These are just some quick guesses to get something resembling what we actually see\n",
    "r0, h0, ain, aout, pa, incl = 31.5, 0.035, 5, -5, 128.7, 89.2\n",
    "g1, g2, wg1 = 0.85, -0.2, 0.75\n",
    "\n",
    "raw_model = grater_2hg_disk_model(r0, h0, ain, aout, pa, incl, g1, g2, wg1,\n",
    "                                  cent=wdb.c_star, distance=distance,\n",
    "                                  nx=wdb.nx, ny=wdb.ny, pxscale=wdb.pxscale,\n",
    "                                  flux_max=1080.)\n",
    "\n",
    "quick_implot(raw_model, norm=mpl.colors.LogNorm, norm_kwargs=dict(clip=True), clim='0.00001*99.99%, 99.99%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b7689",
   "metadata": {},
   "source": [
    "For the models in this notebook: we actually generate the models at detector sampling (**not** oversampled), and then subpixellate them before convolution. From my testing, this is much faster than generating the models at the oversampled resolution and has no  impact on fidelity after convolution. However, I can't promise that this will be the case for every target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea21b7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T16:40:41.196947Z",
     "start_time": "2024-05-09T16:40:40.058425Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resample our raw model (if needed), rotate it to the position angles of the observations, multiply it by the coronagraph transmission map for each roll,\n",
    "# and then convolve our raw model with the previously generated PSF grid:\n",
    "\n",
    "model_cube = wdb.convolver.convolve_model(raw_model, wdb.pxscale, wdb.c_star)\n",
    "\n",
    "fig,axes = quick_implot(model_cube, norm=mpl.colors.LogNorm, norm_kwargs=dict(clip=True), clim='0.001*99.99%, 99.99%', show=False)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_title(f'Roll {i+1}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bd582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T16:40:43.598374Z",
     "start_time": "2024-05-09T16:40:43.584145Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the resulting model_cube as our circumstellar signal (CSS) model in the Winnie SpaceRDI object\n",
    "\n",
    "wdb.set_circumstellar_model(model_cube=model_cube)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b03f9",
   "metadata": {},
   "source": [
    "Note: you can also skip a step above by passing the raw model directly into wdb.set_circumstellar_model, which will then convolve it for you.\n",
    "\n",
    "```\n",
    "wdb.set_circumstellar_model(raw_model=raw_model, raw_model_pxscale=wdb.pxscale, raw_model_center=wdb.c_star)\n",
    "```\n",
    "\n",
    "Once the CSS model is set, we can do two big things with it.\n",
    "\n",
    "First, we can forward model it for the current RDI configuration simply by setting forward_model=True in run_rdi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4613751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:58.997588Z",
     "start_time": "2024-05-09T14:49:58.511364Z"
    }
   },
   "outputs": [],
   "source": [
    "fmrdi_reduc = wdb.run_rdi(forward_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec65715",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:49:59.873923Z",
     "start_time": "2024-05-09T14:49:58.998961Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot data, model, and residuals\n",
    "fig,axes,cbar = quick_implot([rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im], cmap='RdBu_r', clim_perc=99.99, show=False,\n",
    "                             cbar=True, cbar_kwargs=dict(pad=0.015), panelsize=(6,5), extent=rdi_reduc.extent, lims=[-7,7], show_ticks=True)\n",
    "\n",
    "labels = ['Data', 'Model', 'Residuals']\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.set_title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283336fe",
   "metadata": {},
   "source": [
    "Second, we can run Model Constrained RDI by changing our PSF-subtraction presets and then executing run_rdi again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331d26e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:50:03.579039Z",
     "start_time": "2024-05-09T14:50:02.595633Z"
    }
   },
   "outputs": [],
   "source": [
    "wdb.mcrdi_presets() # This effectively asks Winnie to use the currently set circumstellar model to mitigate oversubtraction. See: tutorial 3 for more info\n",
    "\n",
    "mcrdi_reduc = wdb.run_rdi()\n",
    "\n",
    "# For comparison, let's derotate and average our model cube (this shows us the PSF-convolved model without any PSF-subtraction effects --- i.e., 100% algorithmic throughput)\n",
    "model_reduc = wdb.derotate_and_combine_cssmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593c5e47",
   "metadata": {},
   "source": [
    "Note: technically we could forward model our disk model with the MCRDI reduction settings like we did for RDI. E.g.,\n",
    "\n",
    "```\n",
    "wdb.mcrdi_presets()\n",
    "mcrdi_reduc = wdb.run_rdi()\n",
    "fmmcrdi_reduc = wdb.run_rdi(forward_model=True)\n",
    "```\n",
    "\n",
    "However, the results will be the same as for ```wdb.derotate_and_combine_cssmodel()```\n",
    "\n",
    "MCRDI is effectively an inversion of the forward modeling procedure. As such, while we can technically apply forward modeling in the typical framework, it's mathematically circular and doesn't provide any information. \n",
    "\n",
    "You can see this in the plots below, where the residuals panels are identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b09e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:50:04.744075Z",
     "start_time": "2024-05-09T14:50:03.580594Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axes = quick_implot([[rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im],\n",
    "                         [mcrdi_reduc.im, model_reduc.im, mcrdi_reduc.im-model_reduc.im]],\n",
    "                        cmap='RdBu_r', clim_perc=99.99, show=False,\n",
    "                        panelsize=(4.5,5.0), extent=rdi_reduc.extent,\n",
    "                        lims=[-5,5], show_ticks=True)\n",
    "\n",
    "labels = ['Data (RDI)', 'Model (RDI)', 'Residuals (RDI)',\n",
    "          'Data (MCRDI)', 'Model (MCRDI)', 'Residuals (MCRDI)']\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.set_title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9b34d",
   "metadata": {},
   "source": [
    "To think of this in another way: the difference between a standard (unconstrained) RDI reduction and an MCRDI reduction is exactly equal to the effect of forward modeling on the assumed disk model.\n",
    "\n",
    "Note: you can also save the currently set circumstellar signal model using the save_circumstellar_model method, which can later be loaded directly with the set_circumstellar_model method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85092364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:50:53.835533Z",
     "start_time": "2024-05-09T14:50:53.763900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the current disk model to disk\n",
    "wdb.save_circumstellar_model(output_ext='cssmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc55dd55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:51:05.999008Z",
     "start_time": "2024-05-09T14:51:05.964399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model from the files\n",
    "wdb.set_circumstellar_model(model_ext='cssmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bc7c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T16:54:31.947736Z",
     "start_time": "2024-05-09T16:54:31.918004Z"
    },
    "code_folding": [
     4,
     33
    ]
   },
   "outputs": [],
   "source": [
    "# Now, let's a) generalize the GRaTer model to a composite image formed from the super-position of N individual ring-like components, and b) set up an objective function to optimize a disk model for the data.\n",
    "\n",
    "# (we don't actually need more than 1 ring here — I just had the code already and thought it might be helpful for other applications)\n",
    "\n",
    "def grater_nring_2hg_disk_model(cent=np.array([160.,160.]),\n",
    "                                 distance=10., nx=320, ny=320,\n",
    "                                 pxscale=0.063*u.arcsec/u.pixel, accuracy=None, rmax_accuracy=None,\n",
    "                                 polar=False, halfNbSlices=25, **disk_params):\n",
    "    \n",
    "    composite_image = np.zeros((ny,nx))\n",
    "    all_rings_finished = False\n",
    "    i=1\n",
    "    while not all_rings_finished:\n",
    "        ring_params = {}\n",
    "        suffix = f'_{i}'\n",
    "        for pkey in disk_params:\n",
    "            if pkey.endswith(suffix):\n",
    "                ring_params[pkey.replace(suffix, '')] = disk_params[pkey]\n",
    "\n",
    "        if len(ring_params) == 0:\n",
    "            all_rings_finished = True\n",
    "            \n",
    "        else:\n",
    "            F_i = ring_params.pop('F', 1)\n",
    "            composite_image += F_i * grater_2hg_disk_model(**ring_params, cent=cent,\n",
    "                                                            distance=distance, nx=nx, ny=ny,\n",
    "                                                            pxscale=pxscale, accuracy=accuracy, \n",
    "                                                            rmax_accuracy=rmax_accuracy,\n",
    "                                                            polar=polar, halfNbSlices=halfNbSlices)\n",
    "        i+=1\n",
    "    return composite_image\n",
    "\n",
    "\n",
    "def model_rescale_factor(A, B, sig=None, mask=None):\n",
    "    \"\"\"\n",
    "    Determines the value of scalar c such that:\n",
    "        chi^2 = sum [ (A-c*B)^2 / sig^2 ]\n",
    "    is minimized.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    A : numpy.ndarray\n",
    "        Array of measurements\n",
    "    B : numpy.ndarray\n",
    "        Array of model values. Shape must match A and B\n",
    "    sig : numpy.ndarray, optional\n",
    "        The 1 sigma uncertainty for the measurements of A.\n",
    "    mask : numpy.ndarray, optional\n",
    "        A boolean mask with False for entries of A, B, and sig not to be\n",
    "        utilized, and True for entries that are. Defaults to None.\n",
    "    Returns\n",
    "    -------\n",
    "    c : float\n",
    "        The scaling factor to multiply the model (B) by to achieve the minimum chi^2\n",
    "        for measurements (A) having the given uncertainties (sig).\n",
    "    \"\"\"\n",
    "    if np.shape(A) != np.shape(B):\n",
    "        raise ValueError(\"A and B must be arrays of the same shape!\")\n",
    "    if sig is not None:\n",
    "        if np.shape(A) != np.shape(sig):\n",
    "            raise ValueError(\"A, B, and sig must be arrays of the same shape if sig is specified!\")\n",
    "    else:\n",
    "        sig = 1\n",
    "    if mask is None:\n",
    "        c = np.nansum(A * B / (sig ** 2)) / np.nansum((B ** 2) / (sig ** 2))\n",
    "    elif np.shape(mask)[-2:] != np.shape(A)[-2:]:\n",
    "        raise ValueError(\"If provided, mask's shape must match the final axes of A, B, and sig!\")\n",
    "    else:\n",
    "        Amsk, Bmsk = A[..., mask], B[..., mask]\n",
    "        if np.ndim(sig) != 0:\n",
    "            Smsk = sig[..., mask]\n",
    "        else:\n",
    "            Smsk = sig\n",
    "        c = np.nansum(Amsk * Bmsk / (Smsk ** 2)) / np.nansum((Bmsk ** 2) / (Smsk ** 2))\n",
    "    return c\n",
    "\n",
    "\n",
    "def obj_fn(p, rdi_reduc, wdb, roi, distance, err_weighting=False, rmax_accuracy=None,\n",
    "           halfNbSlices=25, return_soln=False, q_clip=None, lsq_sfac=True,\n",
    "           count=True, store_samples=False, clear_each_call=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: lmfit.parameter.Parameters\n",
    "        LMFit parameters object containing at least: r0_1, h0_1, ain_1, aout_1, pa_1, incl_1, g1_1, g2_1, wg1_1\n",
    "        \n",
    "    rdi_reduc: winnie.space.SpaceReduction\n",
    "        An RDI reduction of the data using the current settings in 'wdb', the Winnie SpaceRDI object;\n",
    "        the forward-modeled disk image will be compared to rdi_reduc.im\n",
    "        \n",
    "    wdb: winnie.space.SpaceRDI\n",
    "        The Winnie SpaceRDI object that was used to generate rdi_reduc\n",
    "        \n",
    "    roi: numpy.ndarray\n",
    "        Boolean 'region of interest' array having the same shape as rdi_reduc.im that indicates which\n",
    "        pixels should be included in the goodness of fit evaluation.\n",
    "        \n",
    "    distance: float\n",
    "        Distance to the target star in parsecs.\n",
    "        \n",
    "    err_weighting: bool\n",
    "        If err_weighting is True, the array stored in rdi_reduc.err is used to weight the residuals.\n",
    "        Unless manually changed, rdi_reduc.err is the propagated pixel uncertainty map based on the ERR\n",
    "        FITS extension. Currently, these arrays are not accurate (because they neglect the noise reduction \n",
    "        from SpaceKLIP's use of psuedo reference pixels). This could be useful if you have significant small\n",
    "        separation stellar residuals that are affecting your disk model fit.\n",
    "        \n",
    "    rmax_accuracy: float\n",
    "        The largest separation (in au) at which to calculate the disk model. If None, defaults to the edge\n",
    "        of the FOV.\n",
    "        \n",
    "    halfNbSlices: int\n",
    "        The number of planar slices to compute above and below the disk midplane when generating the raw \n",
    "        disk model.\n",
    "        \n",
    "    return_soln: bool\n",
    "        If True, rather than returning a residual array, returns the forward modeled image and some other items\n",
    "        \n",
    "    q_clip: tuple or list or numpy.ndarray\n",
    "        If not None, q_clip gives a lower and upper quantile bound for the residuals. Any values outside the \n",
    "        quantile range are clipped when evaluating goodness of fit. Can be useful for data with significant \n",
    "        artifacts within the region of interest (e.g., poor reference match, uncorrected hot pixels, etc). \n",
    "        E.g., q_clip = [5,95] will compute goodness of fit using only the inner 5th-95%ile of the distribution \n",
    "        of residual pixel values in your region of interest.\n",
    "    \n",
    "    lsq_sfac: bool\n",
    "        If True, least-squares renormalize the brightness of the forward modeled disk image to match the data\n",
    "        within the region of interest (and considering the uncertainties when err_weighting is True). \n",
    "        This should nearly always be True.\n",
    "        \n",
    "    count: bool\n",
    "        If True, will advance and display a counter during the optimization. Requires setting 'counter = 0' somewhere\n",
    "        outside of the function.\n",
    "        \n",
    "    store_samples: bool\n",
    "        If True, each time obj_fn is called with return_soln=False, an array containing the parameters values and the \n",
    "        corresponding chi-squared metric will be appended to a list titled samples. Requires setting 'samples = []'\n",
    "        somewhere outside of the function.\n",
    "    \n",
    "    clear_each_calls: bool\n",
    "        If True, clears the output every time the function is called. Mostly to prevent accumulating a large number \n",
    "        of print statements if the loop triggers a warning somewhere.\n",
    "    \"\"\"\n",
    "    pdict = p.valuesdict() \n",
    "\n",
    "    if err_weighting:\n",
    "        sig = rdi_reduc.err\n",
    "    else:\n",
    "        sig = None\n",
    "\n",
    "    # Generate the raw model oriented north-up\n",
    "    # We generate a detector-sampled raw model, and then subpixelate it before PSF convolution\n",
    "    # You could alter this to generate an oversampled model quite easily, but in my experience the\n",
    "    # only difference is runtime.\n",
    "    raw_model = grater_nring_2hg_disk_model(**pdict, cent=wdb.c_star, distance=distance,\n",
    "                                            nx=wdb.nx, ny=wdb.ny, pxscale=wdb.pxscale,\n",
    "                                            rmax_accuracy=rmax_accuracy, halfNbSlices=halfNbSlices)\n",
    "\n",
    "    # Convolve the model using the prepared SpaceConvolution object then set it as the CSS model in the SpaceRDI object\n",
    "    wdb.set_circumstellar_model(raw_model=raw_model, raw_model_pxscale=wdb.pxscale, raw_model_center=wdb.c_star)\n",
    "\n",
    "\n",
    "    # Run RDI on the model to get the forward-modeled result\n",
    "    fmrdi_reduc = wdb.run_rdi(forward_model=True, save_products=False, collapse_rolls=return_soln)\n",
    "    \n",
    "    if lsq_sfac:\n",
    "        # Rescale the model to minimize residuals with the data\n",
    "        # Median filter both first to avoid skewing the rescaling with uncorrected hot pixels, etc.\n",
    "        sfac = model_rescale_factor(*median_filter_sequence(np.array([rdi_reduc.im, fmrdi_reduc.im]),\n",
    "                                                            footprint=np.array([[0,1,0],\n",
    "                                                                                [1,1,1],\n",
    "                                                                                [0,1,0]]),\n",
    "                                                            prop_threshold=0.8), sig=sig, mask=roi)\n",
    "    else:\n",
    "        sfac = 1\n",
    "        \n",
    "    fmrdi_reduc.im *= sfac\n",
    "    \n",
    "    if return_soln:\n",
    "        raw_model *= sfac\n",
    "        wdb._csscube *= sfac\n",
    "        return sfac, raw_model, fmrdi_reduc, wdb\n",
    "\n",
    "    res = rdi_reduc.im - fmrdi_reduc.im\n",
    "    \n",
    "    if sig is not None:\n",
    "        res /= sig\n",
    "        \n",
    "    res = res[roi]\n",
    "    \n",
    "    if q_clip is None:\n",
    "        res = np.abs(res)\n",
    "    else:\n",
    "        low,upp = np.nanpercentile(res, q_clip)\n",
    "        res = np.abs(res[(res >= low) & (res <= upp)])\n",
    "        \n",
    "    if clear_each_call:\n",
    "        clear_output()\n",
    "\n",
    "    if count:\n",
    "        global counter\n",
    "        counter += 1\n",
    "        print('Models evaluated: {0: <16}'.format(counter), end='\\r')\n",
    "        \n",
    "    if store_samples: # Append each set of paramaters and the corresponding chisq to a list\n",
    "        chisq = np.nansum(res**2)\n",
    "        sample = [pdict[key] for key in pdict.keys()]\n",
    "        sample.append(chisq)\n",
    "        samples.append(sample)\n",
    "        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badf93e6",
   "metadata": {},
   "source": [
    "For the model optimization procedure below, I'm assuming that the goal is to get a respectable model of the entire disk.\n",
    "\n",
    "This let's us do things like:\n",
    " - perform MCRDI to get a reduction of the data that is ~free of oversubtraction\n",
    " - subtract the disk model to compute better planet detection limits\n",
    " - measure disk brightness from the raw model to avoid PSF convolution effects (which otherwise bias measurements of disk color using multi-band data)\n",
    "\n",
    "However, if you are SOLELY interested in getting an optimal model for MCRDI, we technically only need to model the disk within the optimization zone(s) used for PSF subtraction. Any disk flux outside of the optimization zone(s) cannot induce RDI oversubtraction, and so can be neglected. \n",
    "\n",
    "In this latter scenario, I would recommend adjusting the region of interest mask (```roi``` below) to simply be the map of pixels included in any of your optimzation zones. \n",
    "E.g., \n",
    "\n",
    "```roi = np.any(wdb.optzones, axis=0)```\n",
    "\n",
    "Then, replacing ```wdb.set_crop([201,201])``` with ```wdb.set_crop('auto')``` will automatically crop the FOV to the limits of the optimization zones (plus a few lambda/D padding)\n",
    "\n",
    "Combined, these should dramatically speed up the model optimization. With that said: even if the interest is purely for MCRDI, I'd recommend against defining a very small optimization zone and modeling only a small segment of the disk. In such cases, you could very easily end up fitting the disk model to stellar PSF residuals or artifacts. Be weary if you attempt this and wind up with an inclination and PA that are dramatically different from expectation: you're probably not fitting the actual disk in your optimization region.\n",
    "\n",
    "\n",
    "**Cropping**\n",
    "\n",
    "Cropping the data, as below, can save a significant amount of time in forward modeling. Even if you're working with a disk that spans the entire field of view, if you're using pad_data='auto' you should crop to the original subarray dimensions UNLESS you have bright circumstellar flux falling just outside the nominal FOV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b585bc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T16:54:34.908288Z",
     "start_time": "2024-05-09T16:54:34.392930Z"
    }
   },
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "from winnie.utils import (dist_to_pt, ang_size_to_px_size, ang_size_to_proj_sep, px_size_to_ang_size)\n",
    "\n",
    "# Settings for the radial extent of the region of interest (spanning 0 - 5.5 arcsec in this case)\n",
    "roi_rmax = 5.5 # arcsec\n",
    "roi_rmin = 0.0 # arcsec\n",
    "\n",
    "source_positions = np.array([[-1.06, -3.22], [0.08, -0.48]]) # North-up stellocentric offsets in arcsec (+x is north of star, +y is west of star) of any artifacts or sources you want to exclude from the optimization\n",
    "source_mask_nfwhms = np.array([6, 3]) # Radii of exclusion regions (in lambda/D) for positions above\n",
    "# Source 1 above is the background source a few arcsec south of the star. Source 2 is a group of uncorrected \"bad\" pixels that result in very negative values that may otherwise affect the model \n",
    "\n",
    "# Cropped size to use during optimization. Should be large enough to include the entire disk (or at least the part you're interested in) plus some padding for convolution\n",
    "npx_crop = int(2*(np.ceil(ang_size_to_px_size(roi_rmax, wdb.pxscale).value + 5*wdb._fwhm)))\n",
    "crop_size = [npx_crop, npx_crop] # Cropped shape\n",
    "\n",
    "q_clip = None # see obj_fn docstring\n",
    "err_weighting = False # see obj_fn docstring\n",
    " \n",
    "#####################\n",
    "wdb.rdi_presets() # Set to presets for a standard RDI reduction\n",
    "\n",
    "wdb.set_crop(crop_size)\n",
    "y1,y2,x1,x2 = wdb._crop_indices\n",
    "\n",
    "# Rerun RDI on the cropped data:\n",
    "rdi_reduc = wdb.run_rdi(save_products=False)\n",
    "\n",
    "rmap = dist_to_pt(rdi_reduc.c_star, rdi_reduc.nx, rdi_reduc.ny) # Generate a map of the distance of each pixel from the position of the star (in pixels).\n",
    "\n",
    "# Build our region of interest (ROI) mask; should be True where we want to optimize our disk model and False otherwise\n",
    "roi_cropped = (rmap >= ang_size_to_px_size(roi_rmin, wdb.pxscale).value) & (rmap <= ang_size_to_px_size(roi_rmax, wdb.pxscale).value)\n",
    "for i, spos in enumerate(source_positions):\n",
    "    spos_px = ang_size_to_px_size(spos, wdb.pxscale).value + rdi_reduc.c_star # Convert to pixel position\n",
    "    roi_cropped[dist_to_pt(spos_px, rdi_reduc.nx, rdi_reduc.ny) <= (source_mask_nfwhms[i]*wdb._fwhm)] = False\n",
    "\n",
    "# The largest separation (in au) at which to calculate the disk model. Here, we truncate the calculation at ~ the edge of the cropped FOV\n",
    "rmax_accuracy = ang_size_to_proj_sep(px_size_to_ang_size(npx_crop/2., wdb.pxscale), distance).value # Convert to au\n",
    "\n",
    "fig,(ax1,ax2) = quick_implot([rdi_reduc.im, np.where(roi_cropped, rdi_reduc.im, np.nan)], cmap='RdBu_r', clim_perc=99, show=False, show_ticks=True, extent=rdi_reduc.extent)\n",
    "ax1.set_title('Cropped reduction')\n",
    "ax2.set_title('Region of interest')\n",
    "\n",
    "p = lmfit.Parameters()\n",
    "\n",
    "i = 1 # Ring 1 (the only ring for this example)\n",
    "# Initial parameter guesses:\n",
    "r0, h0, ain, aout, pa, incl, gamma = 35., 0.038, 5, -5, 128.65, 89.08, 1.35 # Dust distribution parameters\n",
    "g1, g2, wg1 = 0.98, 0.5, 0.7 # SPF parameters\n",
    "\n",
    "p.add(f'r0_{i}',    value=r0,     min=r0-10,                max=r0+10,             vary=True)\n",
    "p.add(f'h0_{i}',    value=h0,     min=0.005,                max=0.06,              vary=False)\n",
    "p.add(f'ain_{i}',   value=ain,    min=1,                    max=12,                vary=True)\n",
    "p.add(f'aout_{i}',  value=aout,   min=-12,                  max=-1,                vary=True)\n",
    "p.add(f'pa_{i}',    value=pa,     min=pa-3,                 max=pa+3,              vary=False)\n",
    "p.add(f'incl_{i}',  value=incl,   min=max(incl-2, -89.5),   max=min(incl+2, 89.5), vary=False)\n",
    "p.add(f'gamma_{i}', value=gamma,  min=1.0,                  max=3.0,               vary=True)\n",
    "p.add(f'g1_{i}',    value=g1,     min=-0.99,                max=0.99,              vary=True)\n",
    "p.add(f'g2_{i}',    value=g2,     min=-0.99,                max=0.99,              vary=True)\n",
    "p.add(f'wg1_{i}',   value=wg1,    min=0.51,                 max=1.0,               vary=True)\n",
    "p.add(f'F_{i}',     value=1,      min=0.1,                  max=10,                vary=False) \n",
    "# F_{i} is the overall scaling factor for this ring; should set vary=True for any ring components after the first in a multi-ring geometry\n",
    "# We're using vary=False for ring 1 because we analytically rescale the entire model after forward modeling to minimize residuals much more quickly than optimizing an additional parameter\n",
    "\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77042758",
   "metadata": {},
   "source": [
    "The plot on the right above shows your initial RDI reduction with everything outside the ROI set to NaN (white). To a reasonable approximation, everything that isn't masked should either be disk flux, oversubtraction artifacts, or noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c2da1",
   "metadata": {},
   "source": [
    "Note: the way obj_fn is set up, you can pass in a paramater object ('p' above) containing some additional variables if desired. These include:\n",
    "\n",
    "'beta', which controls the disk's radial flaring\n",
    "\n",
    "'e' and 'omega', which control the disk eccentricity and argument of periastron (the latter in degrees)\n",
    "\n",
    "E.g., to add eccentricity to your disk model, you could add the following lines when setting up your lmfit.Parameters object:\n",
    "\n",
    "```\n",
    "p.add(f'e_{i}',     value=0.,      min=0.,       max=0.5,   vary=True)\n",
    "p.add(f'omega_{i}', value=0.,      min=-180,     max=180,   vary=True)\n",
    "```\n",
    "\n",
    "Additionally, you can include any arbitrary number of ring components. \"i=1\" denotes the first ring. A second could be added by copying and pasting the 'p.add' block above, setting i=2, and adjusting the initial values accordingly.\n",
    "\n",
    "```\n",
    "i = 2 # Ring 2\n",
    "# Initial parameter guesses:\n",
    "r0, h0, ain, aout, pa, incl, gamma = ... # ring 2 values here\n",
    "g1, g2, wg1 = ... # ring 2 values here\n",
    "\n",
    "p.add(f'r0_{i}',    value=r0,     min=r0-10,                max=r0+10,             vary=True)\n",
    "p.add(f'h0_{i}',    value=h0,     min=0.005,                max=0.06,              vary=False)\n",
    "p.add(f'ain_{i}',   value=ain,    min=1,                    max=12,                vary=True)\n",
    "p.add(f'aout_{i}',  value=aout,   min=-12,                  max=-1,                vary=True)\n",
    "p.add(f'pa_{i}',    value=pa,     min=pa-3,                 max=pa+3,              vary=False)\n",
    "p.add(f'incl_{i}',  value=incl,   min=max(incl-2, -89.5),   max=min(incl+2, 89.5), vary=False)\n",
    "p.add(f'gamma_{i}', value=gamma,  min=1.0,                  max=3.0,               vary=True)\n",
    "p.add(f'g1_{i}',    value=g1,     min=-0.99,                max=0.99,              vary=True)\n",
    "p.add(f'g2_{i}',    value=g2,     min=-0.99,                max=0.99,              vary=True)\n",
    "p.add(f'wg1_{i}',   value=wg1,    min=0.51,                 max=1.0,               vary=True)\n",
    "p.add(f'F_{i}',     value=1,      min=0.1,                  max=10,                vary=True) \n",
    "```\n",
    "\n",
    "When adding a second (or more) rings, you'll want to set F_{i} to vary=True for i=2 or above. For one ring, we don't need to vary F as we tune the overall disk brightness analytically after forward modeling anyway. For multiple rings, the value will govern the contrast between the rings and so must be varied. A neat feature in LMFit is that you can set a parameter to be a function of one or more other parameters. So, if you want a two ring geometry where the inclination and PA of the 2nd ring are the same as those of the first, you could just do:\n",
    "\n",
    "```\n",
    "p.add('pa_2', expr='pa_1')\n",
    "p.add('incl_2', expr='incl_1')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9124a",
   "metadata": {},
   "source": [
    "**Note: GRaTer is a very simple scattered-light disk modeling code. I'm using it here because it's very fast. Exercise caution in interpreting the fit parameters.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e977ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T16:54:38.972576Z",
     "start_time": "2024-05-09T16:54:38.165574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run a test model using the initialization and plot the result\n",
    "sfac, model_raw, fmrdi_reduc, wdb = obj_fn(p, rdi_reduc, wdb, roi_cropped, distance, err_weighting=err_weighting,\n",
    "                                           rmax_accuracy=rmax_accuracy, count=False, halfNbSlices=25,\n",
    "                                           return_soln=True, q_clip=q_clip)\n",
    "\n",
    "pim = np.array([rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im])\n",
    "\n",
    "quick_implot(np.where(roi_cropped, pim, np.nan), clim_perc=99., cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71956952",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T14:57:27.713465Z",
     "start_time": "2024-05-09T14:53:50.787313Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carry out the optimization procedure\n",
    "# This requires 498 samples when I run it, and takes ~3.5 minutes on my laptop\n",
    "counter = 0\n",
    "res = lmfit.minimize(obj_fn, p, method='powell',\n",
    "                     args=[rdi_reduc, wdb, roi_cropped, distance], nan_policy='omit',\n",
    "                     kws=dict(err_weighting=err_weighting, rmax_accuracy=rmax_accuracy,\n",
    "                              count=True, halfNbSlices=12, q_clip=q_clip))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182a61a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:05:25.986340Z",
     "start_time": "2024-05-09T15:05:21.131257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uncrop the data, rerun RDI, then reproduce the best fitting model solution\n",
    "y1,y2,x1,x2 = wdb._crop_indices\n",
    "\n",
    "wdb.set_crop()\n",
    "wdb.rdi_presets()\n",
    "rdi_reduc = wdb.run_rdi(save_products=True)\n",
    "\n",
    "roi = np.zeros((rdi_reduc.ny, rdi_reduc.nx), dtype=bool)\n",
    "roi[y1:y2, x1:x2] = roi_cropped\n",
    "\n",
    "sfac, model_raw, fmrdi_reduc, wdb = obj_fn(res.params, rdi_reduc, wdb, roi, distance, err_weighting=err_weighting,\n",
    "                                           rmax_accuracy=None, count=False, halfNbSlices=50, return_soln=True, q_clip=q_clip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f8268",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:05:29.813585Z",
     "start_time": "2024-05-09T15:05:29.253161Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axes = quick_implot([rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im],\n",
    "                        cmap='RdBu_r', clim_perc=99.99, show=False,\n",
    "                        panelsize=(4.5,5.0), extent=rdi_reduc.extent,\n",
    "                        lims=[-5,5], show_ticks=True)\n",
    "\n",
    "labels = ['Data (RDI)', 'Model (RDI)', 'Residuals (RDI)']\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.set_title(labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2415ed",
   "metadata": {},
   "source": [
    "Use our best-fit model to carry out MCRDI\n",
    "\n",
    "Note: our final call to obj_fn already set the best-fit model as the disk model in our SpaceRDI object. So we just need to change our presets to MCRDI and execute run_rdi again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f358b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:05:53.994390Z",
     "start_time": "2024-05-09T15:05:53.011987Z"
    }
   },
   "outputs": [],
   "source": [
    "wdb.mcrdi_presets()\n",
    "mcrdi_reduc = wdb.run_rdi()\n",
    "model_reduc = wdb.derotate_and_combine_cssmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5143cab9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:06:09.238981Z",
     "start_time": "2024-05-09T15:06:08.035589Z"
    }
   },
   "outputs": [],
   "source": [
    "fig,axes = quick_implot([[rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im],\n",
    "                         [mcrdi_reduc.im, model_reduc.im, mcrdi_reduc.im-model_reduc.im]],\n",
    "                        cmap='RdBu_r', clim_perc=99.99, show=False,\n",
    "                        panelsize=(4.5,5.0), extent=rdi_reduc.extent,\n",
    "                        lims=[-5,5], show_ticks=True)\n",
    "\n",
    "labels = ['Data (RDI)', 'Model (RDI)', 'Residuals (RDI)',\n",
    "          'Data (MCRDI)', 'Model (MCRDI)', 'Residuals (MCRDI)']\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.set_title(labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f3e79d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:06:14.581557Z",
     "start_time": "2024-05-09T15:06:13.475797Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate HPFRDI results for comparison:\n",
    "wdb.hpfrdi_presets()\n",
    "hpfrdi_reduc = wdb.run_rdi(save_products=True)\n",
    "fmhpfrdi_reduc = wdb.run_rdi(forward_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d1f4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:08:03.338997Z",
     "start_time": "2024-05-09T15:08:03.136717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make a SpaceReduction object for the raw model as well\n",
    "raw_reduc = winnie.SpaceReduction(spacerdi=wdb, im=model_raw, c_star_out=wdb.c_star, output_ext='rawmodel')\n",
    "\n",
    "# Make a dictionary with some extra info about the best-fit model and optimization settings\n",
    "model_dict = res.params.valuesdict()\n",
    "model_dict.update(dict(sfac=sfac, q_clip=str(q_clip), err_weighting=err_weighting))\n",
    "\n",
    "# For all model-dependent results, add extra model info to the header and then save\n",
    "for reduc in [fmrdi_reduc, mcrdi_reduc, model_reduc, fmhpfrdi_reduc, raw_reduc]:\n",
    "    reduc.primary_header.update(model_dict)\n",
    "    reduc.save(overwrite=True)\n",
    "    \n",
    "# Save the circumstellar model to disk so it can be loaded back with set_circumstellar_model later if needed.\n",
    "wdb.save_circumstellar_model(model_dict=model_dict)\n",
    "    \n",
    "model_params0 = res.params.copy() # Save these for initializing the next filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa51f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:08:10.688551Z",
     "start_time": "2024-05-09T15:08:08.225268Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_args = dict(cmap='RdBu_r', clim_perc=99.99, show=False, panelsize=(4.,4.25),\n",
    "                 extent=rdi_reduc.extent, lims=[-5,5], show_ticks=True)\n",
    "\n",
    "# Plot all three reductions\n",
    "fig,axes = quick_implot([[rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im],\n",
    "                         [mcrdi_reduc.im, model_reduc.im, mcrdi_reduc.im-model_reduc.im],\n",
    "                         [hpfrdi_reduc.im, fmhpfrdi_reduc.im, hpfrdi_reduc.im-fmhpfrdi_reduc.im]], **plot_args)\n",
    "\n",
    "labels = ['Data (RDI)', 'Model (RDI)', 'Residuals (RDI)',\n",
    "          'Data (MCRDI)', 'Model (MCRDI)', 'Residuals (MCRDI)',\n",
    "          'Data (HPFRDI)', 'Model (HPFRDI)', 'Residuals (HPFRDI)']\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.set_title(labels[i], fontsize=18)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_major_locator(mpl.ticker.MaxNLocator(5, integer=True, min_n_ticks=5))\n",
    "        axis.set_major_formatter(\"${x:0.0f}''$\")\n",
    "\n",
    "plt.savefig(raw_reduc.filename.replace('_rawmodel.fits', '_reducs.pdf'), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9cbe60",
   "metadata": {},
   "source": [
    "# Carry out the same procedure for the F444W (but more compactly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606dacc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:08:22.162609Z",
     "start_time": "2024-05-09T15:08:20.692950Z"
    }
   },
   "outputs": [],
   "source": [
    "wdb.load_concat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8458b9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:08:26.580829Z",
     "start_time": "2024-05-09T15:08:26.073711Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup up for forward model optimization\n",
    "# Only recalculating the settings that might change between concats (e.g., for different pxscale and PSF FWHM)\n",
    "npx_crop = int(2*(np.ceil(winnie.utils.ang_size_to_px_size(roi_rmax, wdb.pxscale).value + 5*wdb._fwhm)))\n",
    "crop_size = [npx_crop,npx_crop] # Cropped shape\n",
    "\n",
    "#####################\n",
    "wdb.rdi_presets() # Set to presets for a standard RDI reduction to be safe\n",
    "wdb.set_crop(crop_size)\n",
    "\n",
    "y1,y2,x1,x2 = wdb._crop_indices\n",
    "rdi_reduc = wdb.run_rdi(save_products=False)\n",
    "\n",
    "rmap = winnie.utils.dist_to_pt(rdi_reduc.c_star, rdi_reduc.nx, rdi_reduc.ny) # Generate a map of the distance of each pixel from the position of the star (in pixels).\n",
    "\n",
    "# Build our region of interest (ROI) mask; should be True where we want to optimize our disk model and False otherwise\n",
    "roi_cropped = (rmap >= winnie.utils.ang_size_to_px_size(roi_rmin, wdb.pxscale).value) & (rmap <= winnie.utils.ang_size_to_px_size(roi_rmax, wdb.pxscale).value)\n",
    "for i, spos in enumerate(source_positions):\n",
    "    spos_px = winnie.utils.ang_size_to_px_size(spos, wdb.pxscale).value + rdi_reduc.c_star\n",
    "    roi_cropped[winnie.utils.dist_to_pt(spos_px, rdi_reduc.nx, rdi_reduc.ny) <= (source_mask_nfwhms[i]*wdb._fwhm)] = False\n",
    "\n",
    "# The largest separation (in au) at which to calculate the disk model. Here, we truncate the calculation at ~ the edge of the cropped FOV\n",
    "rmax_accuracy = ang_size_to_proj_sep(px_size_to_ang_size(npx_crop/2., wdb.pxscale), distance).value # Convert to au\n",
    "\n",
    "fig,(ax1,ax2) = quick_implot([rdi_reduc.im, np.where(roi_cropped, rdi_reduc.im, np.nan)], cmap='RdBu_r', clim_perc=99, show=False, show_ticks=True, extent=rdi_reduc.extent)\n",
    "ax1.set_title('Cropped reduction')\n",
    "ax2.set_title('Region of interest')\n",
    "\n",
    "p = model_params0.copy()\n",
    "for param in p:\n",
    "    if not param.startswith('g1_') and not param.startswith('g2_') and not param.startswith('wg1_'):\n",
    "        p[param].vary = False\n",
    "        \n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc2bb1",
   "metadata": {},
   "source": [
    "Note: the two negative spots in the ~ lower right are clearly artifacts, but are far enough away from the disk that they're unlikely to affect the result. You can always add these points to your \"source positions\" list, if you're concerned about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86afca9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:08:33.000830Z",
     "start_time": "2024-05-09T15:08:32.157510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run a test model using the initialization and plot the result\n",
    "sfac, model_raw, fmrdi_reduc, wdb = obj_fn(p, rdi_reduc, wdb, roi_cropped, distance, err_weighting=err_weighting,\n",
    "                                           rmax_accuracy=rmax_accuracy, count=False, halfNbSlices=25,\n",
    "                                           return_soln=True, q_clip=q_clip)\n",
    "\n",
    "pim = np.array([rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im])\n",
    "\n",
    "quick_implot(np.where(roi_cropped, pim, np.nan), clim_perc=99., cmap='RdBu_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75f8d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:11:45.838023Z",
     "start_time": "2024-05-09T15:08:45.205952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Carry out the optimization procedure; should be faster varying only 3 parameters here.\n",
    "# This requires 378 samples when I run it, and takes ~3 minutes on my laptop\n",
    "counter = 0\n",
    "res = lmfit.minimize(obj_fn, p, method='powell',\n",
    "                     args=[rdi_reduc, wdb, roi_cropped, distance], nan_policy='omit',\n",
    "                     kws=dict(err_weighting=err_weighting, rmax_accuracy=rmax_accuracy,\n",
    "                              count=True, halfNbSlices=12, q_clip=q_clip))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13690722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T15:11:55.723683Z",
     "start_time": "2024-05-09T15:11:45.839531Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Uncrop the data, rerun RDI, then reproduce the best fitting model solution\n",
    "y1,y2,x1,x2 = wdb._crop_indices\n",
    "\n",
    "wdb.set_crop()\n",
    "wdb.rdi_presets()\n",
    "rdi_reduc = wdb.run_rdi(save_products=True)\n",
    "\n",
    "roi = np.zeros((rdi_reduc.ny, rdi_reduc.nx), dtype=bool)\n",
    "roi[y1:y2, x1:x2] = roi_cropped\n",
    "\n",
    "sfac, model_raw, fmrdi_reduc, wdb = obj_fn(res.params, rdi_reduc, wdb, roi, distance, err_weighting=err_weighting,\n",
    "                                           rmax_accuracy=None,\n",
    "                                           count=False, halfNbSlices=50,\n",
    "                                           return_soln=True, q_clip=q_clip)\n",
    "\n",
    "# Run MCRDI\n",
    "wdb.mcrdi_presets()\n",
    "mcrdi_reduc = wdb.run_rdi()\n",
    "model_reduc = wdb.derotate_and_combine_cssmodel()\n",
    "\n",
    "# Run HPFRDI:\n",
    "wdb.hpfrdi_presets()\n",
    "hpfrdi_reduc = wdb.run_rdi(save_products=True)\n",
    "fmhpfrdi_reduc = wdb.run_rdi(forward_model=True)\n",
    "\n",
    "# Make a SpaceReduction object for the raw model as well\n",
    "raw_reduc = winnie.SpaceReduction(spacerdi=wdb, im=model_raw, c_star_out=wdb.c_star, output_ext='rawmodel')\n",
    "\n",
    "# Make a dictionary with some extra info about the best-fit model and optimization settings\n",
    "model_dict = res.params.valuesdict()\n",
    "model_dict.update(dict(sfac=sfac, q_clip=str(q_clip), err_weighting=err_weighting))\n",
    "# For all model-dependent results, add extra model info to the header and then save\n",
    "for reduc in [fmrdi_reduc, mcrdi_reduc, model_reduc, fmhpfrdi_reduc, raw_reduc]:\n",
    "    reduc.primary_header.update(model_dict)\n",
    "    reduc.save(overwrite=True)\n",
    "    \n",
    "# Save the circumstellar model to disk so it can be loaded back with set_circumstellar_model later if needed.\n",
    "wdb.save_circumstellar_model(model_dict=model_dict)\n",
    "    \n",
    "plot_args = dict(cmap='RdBu_r', clim_perc=99.99, show=False, panelsize=(4.,4.25),\n",
    "                 extent=rdi_reduc.extent, lims=[-5,5], show_ticks=True)\n",
    "\n",
    "# Plot all three reductions\n",
    "fig,axes = quick_implot([[rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im],\n",
    "                         [mcrdi_reduc.im, model_reduc.im, mcrdi_reduc.im-model_reduc.im],\n",
    "                         [hpfrdi_reduc.im, fmhpfrdi_reduc.im, hpfrdi_reduc.im-fmhpfrdi_reduc.im]], **plot_args)\n",
    "\n",
    "labels = ['Data (RDI)', 'Model (RDI)', 'Residuals (RDI)',\n",
    "          'Data (MCRDI)', 'Model (MCRDI)', 'Residuals (MCRDI)',\n",
    "          'Data (HPFRDI)', 'Model (HPFRDI)', 'Residuals (HPFRDI)']\n",
    "\n",
    "for i,ax in enumerate(axes):\n",
    "    ax.set_title(labels[i], fontsize=18)\n",
    "    ax.tick_params(labelsize=18)\n",
    "    for axis in [ax.xaxis, ax.yaxis]:\n",
    "        axis.set_major_locator(mpl.ticker.MaxNLocator(5, integer=True, min_n_ticks=5))\n",
    "        axis.set_major_formatter(\"${x:0.0f}''$\")\n",
    "\n",
    "plt.savefig(raw_reduc.filename.replace('_rawmodel.fits', '_reducs.pdf'), bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f981e3",
   "metadata": {},
   "source": [
    "### Of course: you could simply run this procedure in a for-loop over the concatenations (especially for data with more filters!)\n",
    "\n",
    "**This might look something like the following.**\n",
    "\n",
    "Note: you really don't need to run this. It exactly repeats the preceding procedure and is simply provided as a more compact example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0b981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T18:54:09.586896Z",
     "start_time": "2024-05-08T18:46:39.276526Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import lmfit\n",
    "\n",
    "plot_args = dict(cmap='RdBu_r', clim_perc=99.99, show=False, panelsize=(4.,4.25),\n",
    "                 extent=rdi_reduc.extent, lims=[-5,5], show_ticks=True)\n",
    "\n",
    "# Settings for the radial extent of the region of interest (spanning 0.0 - 5.5 arcsec in this case)\n",
    "roi_rmax = 5.5 # arcsec\n",
    "roi_rmin = 0.0 # arcsec\n",
    "\n",
    "source_positions = np.array([[-1.06, -3.22], [0.08, -0.48]]) # North-up stellocentric offsets in arcsec (+x is north of star, +y is west of star) of any artifacts or sources you want to exclude from the optimization\n",
    "source_mask_nfwhms = np.array([6, 3]) # Radii of exclusion regions for positions above in lambda/D\n",
    "\n",
    "q_clip = None \n",
    "err_weighting = False \n",
    "\n",
    "# Initial parameter guesses:\n",
    "r0, h0, ain, aout, pa, incl, gamma = 35., 0.038, 5, -5, 128.65, 89.08, 1.35 # Dust distribution parameters\n",
    "g1, g2, wg1 = 0.98, 0.5, 0.7 # SPF parameters\n",
    "\n",
    "p = lmfit.Parameters()\n",
    "p.add(f'r0_1',    value=r0,     min=r0-10,                max=r0+10,             vary=True)\n",
    "p.add(f'h0_1',    value=h0,     min=0.005,                max=0.06,              vary=False)\n",
    "p.add(f'ain_1',   value=ain,    min=1,                    max=12,                vary=True)\n",
    "p.add(f'aout_1',  value=aout,   min=-12,                  max=-1,                vary=True)\n",
    "p.add(f'pa_1',    value=pa,     min=pa-3,                 max=pa+3,              vary=False)\n",
    "p.add(f'incl_1',  value=incl,   min=max(incl-2, -89.5),   max=min(incl+2, 89.5), vary=False)\n",
    "p.add(f'gamma_1', value=gamma,  min=1.0,                  max=3.0,               vary=True)\n",
    "p.add(f'g1_1',    value=g1,     min=-0.99,                max=0.99,              vary=True)\n",
    "p.add(f'g2_1',    value=g2,     min=-0.99,                max=0.99,              vary=True)\n",
    "p.add(f'wg1_1',   value=wg1,    min=0.51,                 max=1.0,               vary=True)\n",
    "p.add(f'F_1',     value=1,      min=0.1,                  max=10,                vary=False)\n",
    "\n",
    "for j,concat in enumerate(wdb.database.obs):\n",
    "    wdb.load_concat(concat)\n",
    "    \n",
    "    # Cropped size to use during optimization. Should be large enough to include the entire disk (or at least the part you're interested in) plus some padding for convolution\n",
    "    npx_crop = int(2*(np.ceil(winnie.utils.ang_size_to_px_size(roi_rmax, wdb.pxscale).value + 5*wdb._fwhm)))\n",
    "    crop_size = [npx_crop, npx_crop] # Cropped shape\n",
    "\n",
    "    wdb.set_crop(crop_size)\n",
    "    y1,y2,x1,x2 = wdb._crop_indices\n",
    "\n",
    "    # Rerun RDI on the cropped data:\n",
    "    rdi_reduc = wdb.run_rdi(save_products=False)\n",
    "\n",
    "    rmap = dist_to_pt(rdi_reduc.c_star, rdi_reduc.nx, rdi_reduc.ny) # Generate a map of the distance of each pixel from the position of the star (in pixels).\n",
    "\n",
    "    # Build our region of interest (ROI) mask; should be True where we want to optimize our disk model and False otherwise\n",
    "    roi_cropped = (rmap >= ang_size_to_px_size(roi_rmin, wdb.pxscale).value) & (rmap <= ang_size_to_px_size(roi_rmax, wdb.pxscale).value)\n",
    "    for i, spos in enumerate(source_positions):\n",
    "        spos_px = ang_size_to_px_size(spos, wdb.pxscale).value + rdi_reduc.c_star # Convert to pixel position\n",
    "        roi_cropped[dist_to_pt(spos_px, rdi_reduc.nx, rdi_reduc.ny) <= (source_mask_nfwhms[i]*wdb._fwhm)] = False\n",
    "\n",
    "    # The largest separation (in au) at which to calculate the disk model. Here, we truncate the calculation at ~ the edge of the cropped FOV\n",
    "    rmax_accuracy = ang_size_to_proj_sep(px_size_to_ang_size(npx_crop/2., wdb.pxscale), distance).value # Convert to au\n",
    "    \n",
    "    if j > 0: # For each concat after the first, initialize with the previous iteration's best-fit and lock all geometry parameters\n",
    "        p = res.params.copy()\n",
    "        for param in p:\n",
    "            if not param.startswith('g1_') and not param.startswith('g2_') and not param.startswith('wg1_'):\n",
    "                p[param].vary = False\n",
    "    \n",
    "    # Carry out the optimization procedure\n",
    "    counter = 0\n",
    "    res = lmfit.minimize(obj_fn, p, method='powell',\n",
    "                         args=[rdi_reduc, wdb, roi_cropped, distance], nan_policy='omit',\n",
    "                         kws=dict(err_weighting=err_weighting, rmax_accuracy=rmax_accuracy,\n",
    "                                  count=True, halfNbSlices=12, q_clip=q_clip))\n",
    "\n",
    "    # Uncrop the data, rerun RDI, then reproduce the best fitting model solution\n",
    "    y1,y2,x1,x2 = wdb._crop_indices\n",
    "\n",
    "    wdb.set_crop()\n",
    "    wdb.rdi_presets()\n",
    "    rdi_reduc = wdb.run_rdi(save_products=True)\n",
    "\n",
    "    roi = np.zeros((rdi_reduc.ny, rdi_reduc.nx), dtype=bool)\n",
    "    roi[y1:y2, x1:x2] = roi_cropped\n",
    "    \n",
    "    sfac, model_raw, fmrdi_reduc, wdb = obj_fn(res.params, rdi_reduc, wdb, roi, distance, err_weighting=err_weighting,\n",
    "                                               rmax_accuracy=None, count=False, halfNbSlices=50, return_soln=True, q_clip=q_clip)\n",
    "\n",
    "    # MCRDI\n",
    "    wdb.mcrdi_presets()\n",
    "    mcrdi_reduc = wdb.run_rdi()\n",
    "    model_reduc = wdb.derotate_and_combine_cssmodel()\n",
    "\n",
    "    # HPFRDI\n",
    "    wdb.hpfrdi_presets()\n",
    "    hpfrdi_reduc = wdb.run_rdi(save_products=True)\n",
    "    fmhpfrdi_reduc = wdb.run_rdi(forward_model=True)\n",
    "\n",
    "    # Make a SpaceReduction object for the raw model as well, so we can write it to disk\n",
    "    raw_reduc = winnie.SpaceReduction(spacerdi=wdb, im=model_raw, c_star_out=wdb.c_star, output_ext='rawmodel')\n",
    "\n",
    "    # Make a dictionary with some extra info about the best-fit model and optimization settings\n",
    "    model_dict = res.params.valuesdict()\n",
    "    model_dict.update(dict(sfac=sfac, q_clip=str(q_clip), err_weighting=err_weighting))\n",
    "    # For all model-dependent results, add extra model info to the header and then save\n",
    "    for reduc in [fmrdi_reduc, mcrdi_reduc, model_reduc, fmhpfrdi_reduc, raw_reduc]:\n",
    "        reduc.primary_header.update(model_dict)\n",
    "        reduc.save(overwrite=True)\n",
    "        \n",
    "    # Save the circumstellar model to disk so it can be loaded back with set_circumstellar_model later if needed.\n",
    "    wdb.save_circumstellar_model(model_dict=model_dict)\n",
    "    \n",
    "    # Plot all three reductions\n",
    "    fig,axes = quick_implot([[rdi_reduc.im, fmrdi_reduc.im, rdi_reduc.im-fmrdi_reduc.im],\n",
    "                             [mcrdi_reduc.im, model_reduc.im, mcrdi_reduc.im-model_reduc.im],\n",
    "                             [hpfrdi_reduc.im, fmhpfrdi_reduc.im, hpfrdi_reduc.im-fmhpfrdi_reduc.im]], **plot_args)\n",
    "\n",
    "    labels = ['Data (RDI)', 'Model (RDI)', 'Residuals (RDI)',\n",
    "              'Data (MCRDI)', 'Model (MCRDI)', 'Residuals (MCRDI)',\n",
    "              'Data (HPFRDI)', 'Model (HPFRDI)', 'Residuals (HPFRDI)']\n",
    "\n",
    "    for i,ax in enumerate(axes):\n",
    "        ax.set_title(labels[i], fontsize=18)\n",
    "        ax.tick_params(labelsize=18)\n",
    "        for axis in [ax.xaxis, ax.yaxis]:\n",
    "            axis.set_major_locator(mpl.ticker.MaxNLocator(5, integer=True, min_n_ticks=5))\n",
    "            axis.set_major_formatter(\"${x:0.0f}''$\")\n",
    "\n",
    "    plt.savefig(raw_reduc.filename.replace('_rawmodel.fits', '_reducs.pdf'), bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
